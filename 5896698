éå¸¸æ„Ÿè°¢ä½ ç¡®è®¤éœ€æ±‚ï¼Œä¸‹é¢æˆ‘å¸®ä½ æ•´ç†å®Œæ•´çš„é¡¹ç›®æ–‡ä»¶ç»“æ„ä¸ä»£ç æ¸…å•ï¼ŒåŒ…æ‹¬ï¼š
	â€¢	S3 Wrapperï¼ˆæ”¹æˆ AWS CLIï¼‰
	â€¢	MinIO Wrapperï¼ˆä¿æŒ mc CLIï¼‰
	â€¢	APIï¼ˆæ”¯æŒ Copyã€Listï¼Œå¸¦å¹¶å‘éš”ç¦»ã€Request IDã€æ—¥å¿—ã€Swagger ç¤ºä¾‹ï¼‰
	â€¢	æ—¥å¿—æ¨¡å—ï¼ˆæ”¯æŒæŒ‰å¤©åˆ‡å‰²ï¼‰
	â€¢	Dockerfileã€docker-compose
	â€¢	å‹åŠ›æµ‹è¯•è„šæœ¬
	â€¢	CI/CD Pipeline é…ç½®

ğŸ“‚ é¡¹ç›®ç»“æ„

project/
â”œâ”€â”€ app.py               # FastAPI ä¸»ç¨‹åº
â”œâ”€â”€ s3_wrapper.py        # S3 æ“ä½œå°è£… (CLI)
â”œâ”€â”€ minio_wrapper.py     # MinIO æ“ä½œå°è£… (CLI)
â”œâ”€â”€ logger.py            # æ—¥å¿—æ¨¡å—ï¼ˆæŒ‰å¤©åˆ‡å‰²ï¼‰
â”œâ”€â”€ requirements.txt     # Python ä¾èµ–
â”œâ”€â”€ Dockerfile           # Docker é•œåƒé…ç½®
â”œâ”€â”€ docker-compose.yml   # Docker Compose é…ç½®
â”œâ”€â”€ load_test.py         # å¹¶å‘è¯·æ±‚å‹åŠ›æµ‹è¯•è„šæœ¬
â”œâ”€â”€ .env                 # ç¯å¢ƒå˜é‡é…ç½®ï¼ˆä¸è¿›ç‰ˆæœ¬åº“ï¼‰
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ docker-deploy.yml  # CI/CD Pipeline

âœ… è¯¦ç»†ä»£ç æ–‡ä»¶

1. app.py (ä¸» API)

ğŸ‘‰ æ”¯æŒ Copyã€Listã€Request IDã€ä¸´æ—¶ç›®å½•éš”ç¦»ã€CLI è°ƒç”¨ã€‚

import os
import uuid
import shutil
import subprocess
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel, Field
from logger import logger
from s3_wrapper import s3_copy, s3_list
from minio_wrapper import minio_copy, minio_list

app = FastAPI()

class CopyRequest(BaseModel):
    source_type: str = Field(..., example="s3")
    source_bucket: str = Field(..., example="source-bucket")
    source_object: str = Field(..., example="folder/")
    destination_type: str = Field(..., example="minio")
    destination_bucket: str = Field(..., example="dest-bucket")
    destination_object: str = Field(..., example="backup-folder/")

@app.post("/copy")
async def copy_file(copy_request: CopyRequest = Body(..., example={
    "source_type": "s3",
    "source_bucket": "source-bucket",
    "source_object": "my-folder/",
    "destination_type": "minio",
    "destination_bucket": "dest-bucket",
    "destination_object": "backup-folder/"
})):
    logger.info(f"ğŸ“¥ Received copy request: {copy_request.dict()}")

    request_id = str(uuid.uuid4())
    local_temp_dir = f"/tmp/copy_{request_id}"
    os.makedirs(local_temp_dir, exist_ok=True)

    try:
        local_path = os.path.join(local_temp_dir, os.path.basename(copy_request.source_object.rstrip("/")))

        # ä¸‹è½½
        if copy_request.source_type == "s3":
            s3_copy(copy_request.source_bucket, copy_request.source_object, local_path, download=True)
        elif copy_request.source_type == "minio":
            minio_copy(copy_request.source_bucket, copy_request.source_object, local_path, download=True)
        else:
            raise Exception("Unsupported source type")

        # ä¸Šä¼ 
        if copy_request.destination_type == "s3":
            s3_copy(copy_request.destination_bucket, copy_request.destination_object, local_path, download=False)
        elif copy_request.destination_type == "minio":
            minio_copy(copy_request.destination_bucket, copy_request.destination_object, local_path, download=False)
        else:
            raise Exception("Unsupported destination type")

        logger.info("âœ… Copy completed successfully.")
        return {"message": "Copy completed successfully.", "request_id": request_id}

    except subprocess.CalledProcessError as e:
        logger.error(f"Command failed: {e}")
        raise HTTPException(status_code=500, detail=f"Command failed: {e}")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        try:
            if os.path.exists(local_temp_dir):
                shutil.rmtree(local_temp_dir)
                logger.info(f"ğŸ§¹ Temporary directory {local_temp_dir} cleaned up.")
        except Exception as cleanup_error:
            logger.warning(f"Temporary directory cleanup failed: {cleanup_error}")

@app.post("/list")
async def list_objects(copy_request: CopyRequest):
    logger.info(f"ğŸ“¥ Received list request: {copy_request.dict()}")

    try:
        if copy_request.source_type == "s3":
            object_list = s3_list(copy_request.source_bucket, copy_request.source_object)
        elif copy_request.source_type == "minio":
            object_list = minio_list(copy_request.source_bucket, copy_request.source_object)
        else:
            raise Exception("Unsupported source type")

        logger.info("âœ… List completed successfully.")
        return {"objects": object_list}

    except subprocess.CalledProcessError as e:
        logger.error(f"List command failed: {e}")
        raise HTTPException(status_code=500, detail=f"List command failed: {e}")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

2. s3_wrapper.py (AWS CLI æ“ä½œå°è£…)

import subprocess
from logger import logger

def s3_copy(bucket, key, local_path, download=True):
    if download:
        cmd = f"aws s3 cp s3://{bucket}/{key} {local_path} --recursive"
        logger.info(f"Downloading from S3: {cmd}")
    else:
        cmd = f"aws s3 cp {local_path} s3://{bucket}/{key} --recursive"
        logger.info(f"Uploading to S3: {cmd}")

    subprocess.run(cmd, shell=True, check=True)

def s3_list(bucket, prefix):
    cmd = f"aws s3 ls s3://{bucket}/{prefix} --recursive"
    logger.info(f"Listing S3 objects: {cmd}")

    result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
    return [line for line in result.stdout.strip().split("\n") if line]

3. minio_wrapper.py (MinIO CLI æ“ä½œå°è£…)

import subprocess
from logger import logger

def minio_copy(bucket, key, local_path, download=True):
    if download:
        cmd = f"mc cp --recursive minio/{bucket}/{key} {local_path}"
        logger.info(f"Downloading from MinIO: {cmd}")
    else:
        cmd = f"mc cp --recursive {local_path} minio/{bucket}/{key}"
        logger.info(f"Uploading to MinIO: {cmd}")

    subprocess.run(cmd, shell=True, check=True)

def minio_list(bucket, prefix):
    cmd = f"mc ls --recursive minio/{bucket}/{prefix}"
    logger.info(f"Listing MinIO objects: {cmd}")

    result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
    return [line for line in result.stdout.strip().split("\n") if line]

4. logger.py (æ”¯æŒæ—¥å¿—åˆ‡å‰²)

import logging
from logging.handlers import TimedRotatingFileHandler
import os
from dotenv import load_dotenv

load_dotenv()

log_level = os.getenv("LOG_LEVEL", "INFO").upper()
log_dir = "logs"
os.makedirs(log_dir, exist_ok=True)

log_file = os.path.join(log_dir, "app.log")

file_handler = TimedRotatingFileHandler(log_file, when="midnight", interval=1, backupCount=7)
file_handler.suffix = "%Y-%m-%d"
file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

logging.basicConfig(
    level=log_level,
    handlers=[
        file_handler,
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

5. requirements.txt

fastapi
uvicorn
python-dotenv

6. Dockerfile

FROM python:3.9

WORKDIR /app

COPY . /app

RUN pip install --no-cache-dir -r requirements.txt

EXPOSE 8000

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]

7. docker-compose.yml

version: "3"
services:
  copy-service:
    build: .
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - LOG_LEVEL=DEBUG

8. load_test.py (å‹åŠ›æµ‹è¯•)

import requests
import threading

URL = "http://your-ec2-ip:8000/copy"

payload = {
    "source_type": "minio",
    "source_bucket": "your-bucket",
    "source_object": "your-folder/",
    "destination_type": "s3",
    "destination_bucket": "your-dest-bucket",
    "destination_object": "backup/"
}

def send_request():
    response = requests.post(URL, json=payload)
    print(response.status_code, response.json())

threads = []
for i in range(10):
    t = threading.Thread(target=send_request)
    threads.append(t)
    t.start()

for t in threads:
    t.join()

print("ğŸš€ å¹¶å‘è¯·æ±‚å®Œæˆ")

9. .github/workflows/docker-deploy.yml

name: Build and Deploy

on:
  push:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Dependencies
      run: pip install -r requirements.txt

    - name: Run Lint
      run: |
        pip install flake8
        flake8 .

    - name: Build Docker Image
      run: docker build -t your-dockerhub-username/copy-service:latest .

    - name: Push Docker Image
      run: |
        echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin
        docker push your-dockerhub-username/copy-service:latest

âœ… å¦‚æœä½ åŒæ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ ï¼š
	1.	è¡¥ä¸€ä¸ªå¥åº·æ£€æŸ¥ APIï¼ˆ/healthï¼‰
	2.	å¸®ä½ å†™ .env ç¤ºä¾‹
	3.	å¸®ä½ å†™éƒ¨ç½²æ–‡æ¡£

è¦ç»§ç»­å¸®ä½ åšå—ï¼ŸğŸ˜Š
