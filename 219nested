import argparse
import fastavro
import pyarrow as pa
import pyarrow.parquet as pq
import pandas as pd

def convert_avro_type_to_arrow(field_type):
    """Manually convert Avro field types to PyArrow types, avoid nullable types like ['null', 'int']"""
    if isinstance(field_type, dict):  # Complex types, such as record
        if field_type.get('type') == 'record':
            # For record types, recursively handle its internal fields
            return pa.struct([
                pa.field(f['name'], convert_avro_type_to_arrow(f['type']))
                for f in field_type['fields']
            ])
        elif field_type.get('type') == 'array':
            # For array types, handle its item types
            item_type = field_type.get('items')
            return pa.list_(convert_avro_type_to_arrow(item_type))
    elif isinstance(field_type, list):  # Union types (nullable)
        # We exclude 'null' from union types to avoid nullable fields
        return pa.union([convert_avro_type_to_arrow(t) for t in field_type if t != 'null'])
    elif isinstance(field_type, str):  # Primitive types
        if field_type == 'string':
            return pa.string()
        elif field_type == 'int':
            return pa.int32()  # Force 'int' to be int32 (32-bit integer)
        elif field_type == 'long':
            return pa.int64()  # 'long' as int64 (64-bit integer)
        elif field_type == 'float':
            return pa.float32()  # 'float' as float32
        elif field_type == 'double':
            return pa.float64()  # 'double' as float64
        elif field_type == 'boolean':
            return pa.bool_()  # 'boolean' as bool
        else:
            return pa.string()  # Default to string type if unknown type
    else:
        return pa.string()  # Default to string type for unknown types

def avro_to_parquet(avro_file_path, parquet_file_path):
    """Convert Avro file to Parquet file"""
    with open(avro_file_path, 'rb') as avro_file:
        reader = fastavro.reader(avro_file)
        schema = reader.schema

        # Print out the field types in the Avro schema
        print("Avro Schema Fields and Types:")
        for field in schema['fields']:
            field_name = field['name']
            field_type = field['type']
            print(f"Field name: {field_name}, Field type: {field_type}")

        # Convert schema into Arrow schema dynamically
        arrow_schema = pa.schema([
            pa.field(field['name'], convert_avro_type_to_arrow(field['type']))
            for field in schema['fields']
        ])

        # Read records and convert them to pandas DataFrame
        records = [record for record in reader]
        df = pd.DataFrame(records)

        # Clean the data: fill NaN values and convert types
        df = df.fillna('')  # You can change the default value if needed
        df = df.convert_dtypes()  # Automatically converts data types to compatible types

        # Convert pandas DataFrame to pyarrow Table
        arrow_table = pa.Table.from_pandas(df, schema=arrow_schema)

        # Write the Arrow Table to Parquet
        pq.write_table(arrow_table, parquet_file_path)

    print(f"Avro file {avro_file_path} has been successfully converted to Parquet at {parquet_file_path}")

def main():
    # Set up argument parser for command-line input
    parser = argparse.ArgumentParser(description="Convert Avro to Parquet")
    parser.add_argument("avro_file", help="Input Avro file path")  # Input Avro file path
    parser.add_argument("parquet_file", help="Output Parquet file path")  # Output Parquet file path
    args = parser.parse_args()

    # Call the conversion function
    avro_to_parquet(args.avro_file, args.parquet_file)

if __name__ == "__main__":
    main()
